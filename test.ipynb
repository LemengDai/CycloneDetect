{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8cca34-956d-4eff-bc37-fac06c6b33e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/lemengdai/.local/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in /home/lemengdai/.local/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: torchmetrics in /home/lemengdai/.local/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/lemengdai/.local/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: filelock in /home/lemengdai/.local/lib/python3.10/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: jinja2 in /home/lemengdai/.local/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy in /home/lemengdai/.local/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/lemengdai/.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/lemengdai/.local/lib/python3.10/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/lemengdai/.local/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/lemengdai/.local/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/lemengdai/.local/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/lemengdai/.local/lib/python3.10/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/lemengdai/.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/lemengdai/.local/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/lemengdai/.local/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/lemengdai/.local/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/lemengdai/.local/lib/python3.10/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: typing-extensions in /home/lemengdai/.local/lib/python3.10/site-packages (from torch) (4.6.3)\n",
      "Requirement already satisfied: networkx in /home/lemengdai/.local/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (59.6.0)\n",
      "Requirement already satisfied: lit in /home/lemengdai/.local/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.5.post0)\n",
      "Requirement already satisfied: cmake in /home/lemengdai/.local/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/lemengdai/.local/lib/python3.10/site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: requests in /home/lemengdai/.local/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: numpy in /home/lemengdai/.local/lib/python3.10/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: packaging in /home/lemengdai/.local/lib/python3.10/site-packages (from torchmetrics) (23.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.7.0 in /home/lemengdai/.local/lib/python3.10/site-packages (from torchmetrics) (0.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/lemengdai/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lemengdai/.local/lib/python3.10/site-packages (from requests->torchvision) (2.0.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lemengdai/.local/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lemengdai/.local/lib/python3.10/site-packages (from requests->torchvision) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/lemengdai/.local/lib/python3.10/site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/lemengdai/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cffd1a41-9aaa-4783-a16c-fdd8736ff030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d99ccbb2-278a-448b-a259-04d0911ff969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from torch.optim import Adam, SGD\n",
    "from collections import OrderedDict\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b23d07",
   "metadata": {},
   "source": [
    "Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f826f3c9-32af-4361-b8b0-6ec50b9c3fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n",
    "        \"\"\"\n",
    "        Initialize ConvLSTM cell.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            Number of channels of input tensor.\n",
    "        hidden_dim: int\n",
    "            Number of channels of hidden state.\n",
    "        kernel_size: (int, int)\n",
    "            Size of the convolutional kernel.\n",
    "        bias: bool\n",
    "            Whether or not to add the bias.\n",
    "        \"\"\"\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim, out_channels=4 * self.hidden_dim, kernel_size=self.kernel_size, padding=self.padding, bias=self.bias)\n",
    "        \n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "        \n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)\n",
    "        \n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "        \n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        \n",
    "        return h_next, c_next\n",
    "    \n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device), torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5ba9d57-53bc-4592-9698-480324e9c39f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers, batch_first=False, bias=True, return_all_layers=False):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            input_dim: Number of channels in input\n",
    "            hidden_dim: Number of hidden channels\n",
    "            kernel_size: Size of kernel in convolutions\n",
    "            num_layers: Number of LSTM layers stacked on each other\n",
    "            batch_first: Whether or not dimension 0 is the batch or not\n",
    "            bias: Bias or no bias in Convolution\n",
    "            return_all_layers: Return the list of computations for all layers\n",
    "        Input:\n",
    "            A tensor of size B, T, W, H, C or T, B, W, H, C\n",
    "        Output:\n",
    "            A tuple of two lists of length num_layers (or length 1 if return_all_layers is False).\n",
    "                0 - layer_output_list is the list of lists of length T of each output\n",
    "                1 - last_state_list is the list of last states\n",
    "                        each element of the list is a tuple (h, c) for hidden state and memory\n",
    "        Example:\n",
    "            >> x = torch.rand((32, 10, 64, 128, 128))\n",
    "            >> convlstm = ConvLSTM(64, 16, 3, 1, True, True, False)\n",
    "            >> _, last_states = convlstm(x)\n",
    "            >> h = last_states[0][0]  # 0 for layer index, 0 for h index\n",
    "        \"\"\"\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        \n",
    "        self._check_kernel_size_consistency(kernel_size)\n",
    "        \n",
    "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
    "        hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers)\n",
    "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
    "            raise ValueError('Inconsistent list length.')\n",
    "            \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "        \n",
    "        cell_list = []\n",
    "        for i in range(self.num_layers):\n",
    "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
    "            cell_list.append(ConvLSTMCell(input_dim=cur_input_dim, hidden_dim=self.hidden_dim[i], kernel_size=self.kernel_size[i], bias=self.bias))\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "        \n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_tensor:\n",
    "            5-D Tensor either of shape (t, b, w, h, c) or (b, t, w, h, c)\n",
    "        hidden_state: \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        last_state_list, layer_output\n",
    "        \"\"\"\n",
    "        if not self.batch_first:\n",
    "            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
    "            \n",
    "        b,_,w,h,_ = input_tensor.size()\n",
    "        \n",
    "        if hidden_state is None:\n",
    "            hidden_state = self._init_hidden(batch_size=b, image_size=(h, w))\n",
    "            \n",
    "        layer_output_list = []\n",
    "        last_state_list = []\n",
    "        \n",
    "        seq_len = input_tensor.size(1)\n",
    "        cur_layer_input = input_tensor\n",
    "        \n",
    "        for layer_idx in range(self.num_layers):\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t in range(seq_len):\n",
    "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :], cur_state=[h, c])\n",
    "                output_inner.append(h)\n",
    "                \n",
    "            layer_output = torch.stack(output_inner, dim=1)\n",
    "            cur_layer_input = layer_output\n",
    "            \n",
    "            layer_output_list.append(layer_output)\n",
    "            last_state_list.append([h, c])\n",
    "            \n",
    "        # give the last layer\n",
    "        if not self.return_all_layers:\n",
    "            layer_output_list = layer_output_list[-1:]\n",
    "            last_state_list = last_state_list[-1:]\n",
    "        \n",
    "        return layer_output_list, last_state_list\n",
    "    \n",
    "    def _init_hidden(self, batch_size, image_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n",
    "        return init_states\n",
    "    \n",
    "    @staticmethod\n",
    "    def _check_kernel_size_consistency(kernel_size):\n",
    "        if not (isinstance(kernel_size, tuple) or (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
    "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
    "    \n",
    "    @staticmethod\n",
    "    def _extend_for_multilayer(param, num_layers):\n",
    "        if not isinstance(param, list):\n",
    "            param = [param] * num_layers\n",
    "        return param\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40391a5b-e016-460f-8f35-8337ebdf477e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = 6\n",
    "OUTPUT_DIM = 1\n",
    "BATCH_SIZE = 16\n",
    "kernel_size = (3, 3)\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca469c25-96c4-428e-ad8b-1cf95d658ade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = ConvLSTM(input_dim=INPUT_DIM,\n",
    "                 hidden_dim=[6, 12, OUTPUT_DIM],\n",
    "                 kernel_size=(3, 3),\n",
    "                 num_layers=3,\n",
    "                 batch_first=True,\n",
    "                 bias=True,\n",
    "                 return_all_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c2e0647-9c9b-4a49-a560-8921c46d21e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, num_layers):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.sequential = nn.Sequential()\n",
    "        self.sequential.add_module(\"conlstm1\", ConvLSTM(input_dim, 64, kernel_size, 1))\n",
    "        self.sequential.add_module(\"batchnorm1\", nn.BatchNorm3d(num_features=output_dim))\n",
    "        \n",
    "        for i in range(2, num_layers + 1):\n",
    "            self.sequential.add_module(\n",
    "                f\"convlstm{i}\", ConvLSTM(64, 64, kernel_size, 1)\n",
    "                )\n",
    "            self.sequential.add_module(\n",
    "                f\"batchnorm1{i}\", nn.BatchNorm3d(num_features=64)\n",
    "            )\n",
    "            \n",
    "        self.conv = nn.Conv2d(in_channels=input_dim, out_channels=output_dim, kernel_size=kernel_size)\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        output = self.sequential(input_tensor)\n",
    "        output = self.conv(output[:,:,-1])\n",
    "        return nn.Sigmoid()(output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ec419f5-7fcc-43ec-a6f9-432245b1aa93",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (264854284.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    model2 = Seq2Seq(input_dim=INPUT_DIM, output_dim=OUTPUT_DIM,kernel_size=(3, 3), num_layers=2).\u001b[0m\n\u001b[0m                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model2 = Seq2Seq(input_dim=INPUT_DIM, output_dim=OUTPUT_DIM,kernel_size=(3, 3), num_layers=2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcad84a3-a408-4089-90b5-9b8cef043583",
   "metadata": {},
   "outputs": [],
   "source": [
    "convlstm_encoder_params = [\n",
    "    [\n",
    "        OrderedDict({'conv1_leaky_1': [INPUT_DIM, 8, 7]}),\n",
    "        OrderedDict({'conv2_leaky_1': [64, 128, 5]}),\n",
    "        OrderedDict({'conv3_leaky_1': [192, 192, 3]}),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        ConvLSTM(8, 64, kernel_size, 1),\n",
    "        ConvLSTM(128, 192, kernel_size, 1),\n",
    "        ConvLSTM(192, 192, kernel_size, 1),\n",
    "    ]\n",
    "]\n",
    "\n",
    "convlstm_decoder_params = [\n",
    "    [\n",
    "        OrderedDict({'deconv1_leaky_1': [192, 192, 4]}),\n",
    "        OrderedDict({'deconv2_leaky_1': [128, 64, 5]}),\n",
    "        OrderedDict({\n",
    "            'deconv3_leaky_1': [64, 8, 7],\n",
    "            'conv3_leaky_2': [8, 8, 3],\n",
    "            'conv3_3': [8, OUTPUT_DIM, 1]\n",
    "        }),\n",
    "    ],\n",
    "\n",
    "    [\n",
    "        ConvLSTM(192, 128, kernel_size, 1),\n",
    "        ConvLSTM(128, 192, kernel_size, 1),\n",
    "        ConvLSTM(64, 8, kernel_size, 1),\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75d836df-5cb2-441a-b4ee-bd8dd9af2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layers(block):\n",
    "    layers = []\n",
    "    for layer_name, v in block.items():\n",
    "        if 'pool' in layer_name:\n",
    "            layer = nn.MaxPool2d(kernel_size=v[0], stride=v[1],\n",
    "                                    padding=v[2])\n",
    "            layers.append((layer_name, layer))\n",
    "        elif 'deconv' in layer_name:\n",
    "            transposeConv2d = nn.ConvTranspose2d(in_channels=v[0], out_channels=v[1],\n",
    "                                                 kernel_size=v[2])\n",
    "            layers.append((layer_name, transposeConv2d))\n",
    "            if 'relu' in layer_name:\n",
    "                layers.append(('relu_' + layer_name, nn.ReLU(inplace=True)))\n",
    "            elif 'leaky' in layer_name:\n",
    "                layers.append(('leaky_' + layer_name, nn.LeakyReLU(negative_slope=0.2, inplace=True)))\n",
    "        elif 'conv' in layer_name:\n",
    "            conv2d = nn.Conv2d(in_channels=v[0], out_channels=v[1],\n",
    "                               kernel_size=v[2])\n",
    "            layers.append((layer_name, conv2d))\n",
    "            if 'relu' in layer_name:\n",
    "                layers.append(('relu_' + layer_name, nn.ReLU(inplace=True)))\n",
    "            elif 'leaky' in layer_name:\n",
    "                layers.append(('leaky_' + layer_name, nn.LeakyReLU(negative_slope=0.2, inplace=True)))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    return nn.Sequential(OrderedDict(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3141719-edbf-437c-b6c2-a2c1064d415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, subnets, rnns):\n",
    "        super().__init__()\n",
    "        assert len(subnets)==len(rnns)\n",
    "\n",
    "        self.blocks = len(subnets)\n",
    "\n",
    "        for index, (params, rnn) in enumerate(zip(subnets, rnns), 1):\n",
    "            setattr(self, 'stage'+str(index), make_layers(params))\n",
    "            setattr(self, 'rnn'+str(index), rnn)\n",
    "\n",
    "    def forward_by_stage(self, input, subnet, rnn):\n",
    "        input = subnet(input)\n",
    "        outputs_stage, state_stage = rnn(input, None)\n",
    "        \n",
    "        return outputs_stage, state_stage\n",
    "    \n",
    "    def forward(self, input):\n",
    "        hidden_states = []\n",
    "        logging.debug(input.size())\n",
    "        for i in range(1, self.blocks+1):\n",
    "            input, state_stage = self.forward_by_stage(input, getattr(self, 'stage'+str(i)), getattr(self, 'rnn'+str(i)))\n",
    "            hidden_states.append(state_stage)\n",
    "        return tuple(hidden_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "942a75df-9fb5-4b4f-a934-052761efff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, subnets, rnns):\n",
    "        super().__init__()\n",
    "        assert len(subnets) == len(rnns)\n",
    "\n",
    "        self.blocks = len(subnets)\n",
    "\n",
    "        for index, (params, rnn) in enumerate(zip(subnets, rnns)):\n",
    "            setattr(self, 'rnn' + str(self.blocks-index), rnn)\n",
    "            setattr(self, 'stage' + str(self.blocks-index), make_layers(params))\n",
    "\n",
    "    def forward_by_stage(self, input, state, subnet, rnn):\n",
    "        input, state_stage = rnn(input, state)\n",
    "        input = subnet(input)\n",
    "        return input\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        input = self.forward_by_stage(None, hidden_states[-1], getattr(self, 'stage3'),\n",
    "                                      getattr(self, 'rnn3'))\n",
    "        for i in list(range(1, self.blocks))[::-1]:\n",
    "            input = self.forward_by_stage(input, hidden_states[i-1], getattr(self, 'stage' + str(i)),\n",
    "                                                       getattr(self, 'rnn' + str(i)))\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7446f7c1-525c-419b-953a-ec09ba5bf0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, forecaster):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.forecaster = forecaster\n",
    "\n",
    "    def forward(self, input):\n",
    "        state = self.encoder(input)\n",
    "        output = self.forecaster(state)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbcbaab7-40e3-4f01-aebf-9622c944c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(convlstm_encoder_params[0], convlstm_encoder_params[1])\n",
    "decoder = Decoder(convlstm_decoder_params[0], convlstm_decoder_params[1])\n",
    "model3 = EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d3819be-af75-439c-9d9f-f0bf9b516e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLSTM(\n",
      "  (cell_list): ModuleList(\n",
      "    (0): ConvLSTMCell(\n",
      "      (conv): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ConvLSTMCell(\n",
      "      (conv): Conv2d(18, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ConvLSTMCell(\n",
      "      (conv): Conv2d(13, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = model1\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696b3afe",
   "metadata": {},
   "source": [
    "Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6adab2fa-35f3-4e2a-a848-aaa9f2c302a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/hurricane_image_train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m image_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/hurricane_image_train.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m image_train \u001b[38;5;241m=\u001b[39m image_train[:, :, :, :, :, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m      3\u001b[0m label_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/hurricane_label_train.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/hurricane_image_train.npy'"
     ]
    }
   ],
   "source": [
    "image_train = np.load(\"data/hurricane_image_train.npy\")\n",
    "image_train = image_train[:, :, :, :, :, 1:4]\n",
    "label_train = np.load(\"data/hurricane_label_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390bf8b-172e-4225-b14d-313c4f761dba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_train = np.reshape(image_train, (image_train.shape[0]*image_train.shape[1], 10, 128, 257, 3))\n",
    "label_train = np.reshape(label_train, (label_train.shape[0]*label_train.shape[1], 10, 128, 257, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905220f6-506d-472d-a314-e6b6e25c88b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_test = np.load(\"data/hurricane_image_test.npy\")\n",
    "label_test = np.load(\"data/hurricane_label_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c8f2fa-dd4c-4a22-a1ac-8784c603f111",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_test = np.reshape(image_test, (image_test.shape[0]*image_test.shape[1], 10, 128, 257, 3))\n",
    "label_test = np.reshape(label_test, (label_test.shape[0]*label_test.shape[1], 10, 128, 257, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b34c0ed-69cf-4bc6-b4f5-dbf7ee1abac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(image_train.shape)\n",
    "print(label_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee9b89-710b-4a02-92cb-8ac769609001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(image_test.shape)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5ab42b",
   "metadata": {},
   "source": [
    "Data Parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c07282b1-10a7-4c49-9d91-9b24a703df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f42e952b-9364-4f97-8781-f7d7687e9044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Tropical Cyclone Detection Model Training')\n",
    "parser.add_argument('--lr', default=0.1, help='')\n",
    "parser.add_argument('--batch_size', type=int, default=768, help='')\n",
    "parser.add_argument('--max_epochs', type=int, default=4, help='')\n",
    "parser.add_argument('--num_workers', type=int, default=0, help='')\n",
    "\n",
    "parser.add_argument('--init_method', default='tcp://127.0.0.1:3456', type=str, help='')\n",
    "parser.add_argument('--dist_backend', default='gloo', type=str, help='')\n",
    "parser.add_argument('--world_size', default=1, type=int, help='')\n",
    "parser.add_argument('--distributed', action='store_true', help='')\n",
    "args = parser.parse_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07230211-da0e-4e10-9aba-6e1d73f7b6a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      8\u001b[0m current_device \u001b[38;5;241m=\u001b[39m local_rank\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrom Rank: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, ==> Initializing Process Group...\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(rank))\n\u001b[1;32m     14\u001b[0m init_process_group(backend\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdist_backend, init_method\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39minit_method, world_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size, rank\u001b[38;5;241m=\u001b[39mrank)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:350\u001b[0m, in \u001b[0;36mset_device\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    348\u001b[0m device \u001b[38;5;241m=\u001b[39m _get_device_index(device)\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 350\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_setDevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:247\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    246\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 247\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    251\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "ngpus_per_node = torch.cuda.device_count()\n",
    "\n",
    "local_rank = int(os.environ.get(\"SLURM_LOCALID\"))\n",
    "rank = int(os.environ.get(\"SLURM_NODEID\"))*ngpus_per_node + local_rank\n",
    "\n",
    "current_device = local_rank\n",
    "\n",
    "torch.cuda.set_device(current_device)\n",
    "\n",
    "print(\"From Rank: {}, ==> Initializing Process Group...\".format(rank))\n",
    "\n",
    "init_process_group(backend=args.dist_backend, init_method=args.init_method, world_size=args.world_size, rank=rank)\n",
    "print(\"process group ready!\")\n",
    "\n",
    "print(\"From Rank: {}, ==> Making model...\".format(rank))\n",
    "\n",
    "model.cuda()\n",
    "model = DDP(model, device_ids=[current_device])\n",
    "\n",
    "print(\"From Rank: {}, ==> Preparing data...\".format(rank))\n",
    "\n",
    "train_sampler = DistributedSampler(image_train)\n",
    "test_sampler = DistributedSampler(image_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0bb450",
   "metadata": {},
   "source": [
    "Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9473817e-d752-4ffd-b29b-d88441410fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClimateImageDataset(Dataset):\n",
    "    def __init__(self, dataset, labels, transform=None, target_transform=None):\n",
    "        self.ds_labels = labels\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataset[idx]\n",
    "        label = self.ds_labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a35a47-fdf3-443a-8329-092bd92983b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = ClimateImageDataset(image_train, image_test)\n",
    "test_data = ClimateImageDataset(image_test, label_test)\n",
    "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=(train_sampler is None), sampler=train_sampler)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=(test_sampler is None), sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97d21d7d-8154-4b31-80d1-502becf8682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "epochs = 5\n",
    "loss_fn = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a221fe",
   "metadata": {},
   "source": [
    "Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d25a91be-cdd9-4e33-ae48-2babc0144bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice\n",
    "\n",
    "ALPHA = 0.8\n",
    "GAMMA = 2\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, alpha=ALPHA, gamma=GAMMA, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        #first compute binary cross-entropy \n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        BCE_EXP = torch.exp(-BCE)\n",
    "        focal_loss = alpha * (1-BCE_EXP)**gamma * BCE\n",
    "                       \n",
    "        return focal_loss\n",
    "    \n",
    "ALPHA = 0.5\n",
    "BETA = 0.5\n",
    "\n",
    "class TverskyLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(TverskyLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1, alpha=ALPHA, beta=BETA):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = (inputs * targets).sum()    \n",
    "        FP = ((1-targets) * inputs).sum()\n",
    "        FN = (targets * (1-inputs)).sum()\n",
    "       \n",
    "        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n",
    "        \n",
    "        return 1 - Tversky"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56742cb",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c9df9a6-101a-4180-8f18-e16e8f4e4028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, epoch, writer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for batch, (input, target) in enumerate(dataloader):\n",
    "        \n",
    "        input = input.cuda()\n",
    "        target = target.cuda()\n",
    "\n",
    "        pred = model(input)\n",
    "        loss = loss_fn(pred, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(input)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 10,\n",
    "                            epoch * len(dataloader) + batch + 1)\n",
    "            running_loss = 0\n",
    "            \n",
    "            #save model at each checkpoint\n",
    "            ckp = model.module.state_dict()\n",
    "            PATH = \"checkpoint.pt\"\n",
    "            torch.save(ckp, PATH)\n",
    "            print(f\"Epoch {epoch} | Training checkpoint saved at {PATH}\")\n",
    "        \n",
    "        \n",
    "def test_loop(dataloader, model, loss_fn, epoch, writer, func):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0\n",
    "    preds = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, (input, target) in enumerate(dataloader):\n",
    "            pred = model(input)\n",
    "            loss = loss_fn(pred, target).item()\n",
    "            test_loss += loss\n",
    "            preds.append(pred)\n",
    "            targets.append(target)\n",
    "            writer.add_scalar('testing loss', loss, epoch * len(dataloader) + batch + 1)\n",
    "    test_loss = test_loss / num_batches\n",
    "    \n",
    "    if func == Dice:\n",
    "        metric = func(average=\"micro\")\n",
    "    else:\n",
    "        metric = func(task=\"binary\")\n",
    "    score = metric(preds, targets)\n",
    "    print(f\"Test Error: \\n : {metric.__class__.__name__}: {score:.3f}, Avg loss: {test_loss:>8f} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4657871e-3f40-4f3d-8a64-551ccdecc46a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m954.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:01\u001b[0m0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/lemengdai/.local/lib/python3.10/site-packages (from tensorboard) (2.31.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard) (0.37.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard) (59.6.0)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 KB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf>=3.19.6\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.8/181.8 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m678.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m955.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /home/lemengdai/.local/lib/python3.10/site-packages (from tensorboard) (1.24.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting urllib3<2.0\n",
      "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lemengdai/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/lemengdai/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lemengdai/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/lemengdai/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.0)\n",
      "Installing collected packages: werkzeug, urllib3, tensorboard-data-server, pyasn1, protobuf, markdown, grpcio, cachetools, absl-py, rsa, pyasn1-modules, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.0.3\n",
      "    Uninstalling urllib3-2.0.3:\n",
      "      Successfully uninstalled urllib3-2.0.3\n",
      "Successfully installed absl-py-1.4.0 cachetools-5.3.1 google-auth-2.22.0 google-auth-oauthlib-1.0.0 grpcio-1.56.0 markdown-3.4.3 protobuf-4.23.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.1 urllib3-1.26.16 werkzeug-2.3.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cb4e527-db09-47bc-9d77-965c3f17fabd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     train_loop(\u001b[43mtrain_dataloader\u001b[49m, model, loss_fn, optimizer, t\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, writer)\n\u001b[1;32m      7\u001b[0m     test_loop(test_dataloader, model, loss_fn, t\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, writer)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchmetrics\n",
    "from torchmetrics.classification import Dice, Recall, Specificity, Accuracy, Precision, JaccardIndex, AveragePrecision\n",
    "from torch import tensor\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_sampler.set_epoch(t)\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer, t+1, writer)\n",
    "    test_sampler.set_epoch(t)\n",
    "    test_loop(test_dataloader, model, loss_fn, t+1, writer, Dice)\n",
    "\n",
    "destroy_process_group()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8054e0",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3aa02ba-ec9e-4337-8be2-3208e4e5f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOOTH = 1e-6\n",
    "\n",
    "def iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor):\n",
    "    # You can comment out this line if you are passing tensors of equal shape\n",
    "    # But if you are passing output from UNet or something it will most probably\n",
    "    # be with the BATCH x 1 x H x W shape\n",
    "    outputs = outputs.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W\n",
    "    \n",
    "    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
    "    union = (outputs | labels).float().sum((1, 2))         # Will be zero if both are 0\n",
    "    \n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n",
    "    \n",
    "    thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n",
    "    \n",
    "    return thresholded  # Or thresholded.mean() if you are interested in average across the batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "771027e5-64d5-4419-80d3-557a36fc3688",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice: 0.667\n",
      "BinaryRecall: 0.667\n",
      "BinarySpecificity: 0.667\n",
      "BinaryAccuracy: 0.667\n",
      "BinaryPrecision: 0.667\n",
      "BinaryJaccardIndex: 0.500\n",
      "BinaryAveragePrecision: 0.611\n"
     ]
    }
   ],
   "source": [
    "# target = tensor([0, 1, 0, 1, 0, 1])\n",
    "# preds = tensor([0, 0, 1, 1, 0, 1])\n",
    "# preds = preds.to(torch.float32)\n",
    "\n",
    "# dice = Dice(average=\"micro\")\n",
    "# precision = Precision(task=\"binary\")\n",
    "# accuracy = Accuracy(task=\"binary\")\n",
    "# specificity = Specificity(task=\"binary\")\n",
    "# recall = Recall(task=\"binary\")\n",
    "# average_precision = AveragePrecision(task=\"binary\")\n",
    "# jaccard_idx = JaccardIndex(task=\"binary\")\n",
    "\n",
    "# metrics = [Dice, Recall, Specificity, Accuracy, Precision, JaccardIndex, AveragePrecision]\n",
    "\n",
    "# for func in metrics:\n",
    "#     if func == Dice:\n",
    "#         metric = func(average=\"micro\")\n",
    "#     else:\n",
    "#         metric = func(task=\"binary\")\n",
    "#     score = metric(preds, target)\n",
    "#     print(f\"{metric.__class__.__name__}: {score:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
